<!DOCTYPE html>
<html>
    <head>
        <title> Data Science Radar April 14 2023</title>
            <style>
            	blockquote {
            	max-width: 1200px;
            	margin: 20px;
            	padding: 20px;
            	text-align: left;
            	font-family: serif;
            	font-size: 18px;
            	color: #63666a;
            	background-color: #fcf5e5;
            	}
            	ul,li {
                font-family: serif;
            	font-size: 18px;
                line-height: 1.5;
                padding: 8px;
                margin-left: 20px;
                }
                h1 {
                display: block;
                font-weight: bold;
                background: #132A47;
                font-family: Copperplate;
                font-size: 55px;
                color: #FFFFFF;
                padding: 18px;
                margin-left: 20px;   
                }
                h6 {
                display: block;
                font-family: serif;
                font-size: 16px;
                margin-left: 20px;
                font-style: italic;   
                }
                img {
                margin-left: 20px;   
                }
            </style>
    </head>
    <body>
        <h1>Data Science Radar - April 14 2023</h1>
        <img src="https://raw.githubusercontent.com/wcairns/wcairns.github.io/main/_images/WestMonroe.blueyellow.png" alt="West Monroe Logo">

            <blockquote><p>Hi all, <br><br>
            No real shortage of new research and the good and bad developments in Language Models. While I try to publish links that come from a wide range of AI and ML topics it seems the pipeline of traditional ML developments has dried up lately. With the further mainstream uses of applications like ChatGPT, Bard, Dall-E, Midjourney and Stable Diffusion regulators and legislators are starting to take notice and key issues of safety and privacy are coming under greater focus. Iâ€™m reading and hearing more about Fortune 500 Companies taking cautious approaches when it comes to deploying and developing AI Solutions. Otherwise some great stories and papers in this collection so enjoy reading.
            <br><br>
            -Will Cairns</p></blockquote>

            <p><h6> Topics in this edition <br>
            #Python / #AI / #ML / #MLOps</h6></p>

            <ul>
            <li>The FDA's Center for Devices has issued <a href="https://www.fda.gov/medical-devices/medical-devices-news-and-events/cdrh-issues-draft-guidance-predetermined-change-control-plans-artificial-intelligencemachine">Draft Guidance for Artificial Intelligence/Machine Learning-Enabled Medical Devices</a>. Unfortunately right now it looks as trivial as a consumer EULA.</li>


            <li>FinTech pioneer and powerhouse Bloomberg has gotten into the LLM game with <a href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a></li>


            <li>With the development of <a href="https://arxiv.org/abs/2303.17580">HuggingGPT</a>, HuggingFace has built the model to serve models. Authors of the paper claim "it is able to assign the most suitable models for each task and integrate results from different models."</li>


            <li>Following the same logic I have discussed previously, the author of this substack article asks the question <a href="https://iamnotarobot.substack.com/p/should-you-use-openais-embeddings">"Should you use OpenAI's embeddings?"</a>. While I believe many Companies will go this route, the conclusion here indicates  probably not.</li>


            <li>Something to add to our Training Hub. Weights and Biases has a <a href="https://www.wandb.courses/courses/ci-cd-for-machine-learning?utm_source=twitter&utm_medium=social&utm_campaign=Mark-sponsored">free 38 lesson course on CI/CD for Machine Learning</a></li>


            <li>With 20 Years of AI & ML investment behind them, <a href="https://aws.amazon.com/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/">Amazon just announced Bedrock</a>. A new service that makes Foundation Models from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API</li>


            <li>A very pragmatic view on Deep Learning and LLM's from an early skeptic. <a href="https://www.inference.vc/we-may-be-surprised-again/">We May be Surprised Again: Why I take LLMs seriously.</a></li>


            <li>An interview with Jesse Johnson (ex Yale, Google, Dewpoint Therapeutics) and author of the "Scaling Biotech" blog talks <a href="https://serokell.io/blog/interview-with-jesse-johnson">bringing together AI and Medical Research</a></li>


            <li>Google Researchers conducted experiments to further the understanding of <a href="https://arxiv.org/abs/2209.07686">Chain of Thought reasoning in LLM's</a>. The insight into average attention per token identifies that few-shot models are sensitive to patterns.</li>


            <li>With the release of Dolly and now Dolly 2.0, <a href="https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html">Databricks looks to democratize ChatGPT capabilities with open models</a></li>


            <li>By applying Masked Auto-encoders (MAE's) a group of researchers at Meta discover <a href="https://arxiv.org/abs/2303.13496">"The effectiveness of MAE pre-pretraining for billion-scale pretraining"</a></li>


            <li>A bit of criticism of SV's latest darling OpenAI. The key <a href="https://aisnakeoil.substack.com/p/openais-policies-hinder-reproducible">decision to discontinue Codex support</a> will hinder reproducible research on language models</li>


            <li>A Google paper from ICLR 2022 envisions <a href="https://arxiv.org/abs/2203.08913">language models that can simply read and memorize new data at inference time</a>, thus acquiring new knowledge immediately.</li>
            </ul>
    </body>
</html>

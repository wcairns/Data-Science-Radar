<!DOCTYPE html>
<html>
    <head>
        <title> Data Science Radar December 23 2022</title>
            <style>
            	blockquote {
            	max-width: 1200px;
            	margin: 20px;
            	padding: 20px;
            	text-align: left;
            	font-family: serif;
            	font-size: 18px;
            	color: #63666a;
            	background-color: #fcf5e5;
            	}
            	ul,li {
                font-family: serif;
            	font-size: 18px;
                line-height: 1.5;
                padding: 8px;
                margin-left: 20px;
                }
                h1 {
                display: block;
                font-weight: bold;
                background: #132A47;
                font-family: Copperplate;
                font-size: 55px;
                color: #FFFFFF;
                padding: 18px;
                margin-left: 20px;   
                }
                h6 {
                display: block;
                font-family: serif;
                font-size: 16px;
                margin-left: 20px;
                font-style: italic;   
                }
                img {
                margin-left: 20px;   
                }
            </style>
    </head>
    <body>
        <h1>Data Science Radar - December 23 2022</h1>
        <img src="https://raw.githubusercontent.com/wcairns/wcairns.github.io/main/_images/WestMonroe.blueyellow.png" alt="West Monroe Logo">

            <blockquote><p>Hi all, <br><br>
            Lots of great stuff this week as the year winds down and research projects come to completion. Overall I am pleased with the diversity of 
            articles, papers and research topics that I have been able to share with you these past few months. Going into 2023 I have a number of additional
            thoughts on how we can improve collaboration and broaden the reach of this newsletter to people outside of the Tech Practice who may not have 
            the same penchant for deep theory as some of us. I'd also like to present an offer to anyone in our group to have their own shot at being the guest
            author/presenter for a future issue or even just a single article submission. If you think you'd like to participate I'd be happy to share my workflow 
            and talk logististics with you. Happy Holidays!

            <br><br>
            -Will Cairns</p></blockquote>

            <p><h6> Topics in this edition <br>
            #Python / #AI / #ML / #NLP / #HLS</h6></p>

            <ul>
            <li>While TikTok struggles with privacy regulators, the ML Team has done some ground-breaking work with large scale recommenders. In <a href="https://arxiv.org/abs/2209.07663">this paper</a> they discuss solving hash-key collisions, concept drift and real-time online feedback</li>


            <li>A theory heavy paper from researchers at MIT <a href="https://arxiv.org/pdf/2006.04439.pdf">introduces a differential equation solver</a> used inside a neural network applied to time-series data. Their work shows improved performance over RNN and LTSM architectures for certain tasks with improved causality.</li>


            <li>Murray Shanahan, professor of Cognitive Robotics and a senior scientist at DeepMind <a href="https://venturebeat.com/ai/why-we-must-be-careful-about-how-we-speak-of-large-language-models/">discusses the philosophical dangers of assigning human-like capabilities to Large Language Models</a>. </li>


            <li>Looking for a new challenge during your Holiday break? The NFL and Kaggle are running a <a href="https://www.kaggle.com/competitions/nfl-player-contact-detection/overview?utm_source=substack&utm_medium=email">competition to improve detection of external contact</a> experienced by players during an NFL football game.</li>


            <li>A recent paper from Google Research demonstrates that <a href="https://arxiv.org/abs/2212.07677">Transformer Architectures in Neural Networks learn in-context by implementing gradient descent</a> in their forward pass.</li>


            <li>When fine-tuning pre-trained (foundational) models, simply <a href="https://github.com/mlfoundations/task_vectors">altering or interpolating the weight vectors can change how the models behave</a>.</li>


            <li>An article in nature.com talks about improving robustness and explainability for data science applied to clinical research in healthcare.  </li>


            <li>Used by OpenAI and instacart, the <a href="https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray">Ray framework for scaling ML and AI workloads</a> removes a lot of the performance overhead of handling common use-cases and scales to millions of models.</li>


            <li>Are LLMs Sycophants in disguise? <a href="https://github.com/anthropics/evals">This paper</a> analyzes the relationship of model size and the tendency to repeat back a userâ€™s view, for questions on politics, NLP, and philosophy.</li>


            <li>Presented by gretel.ai and supported by NVIDIA, a free <a href="https://gretel.ai/synthesize2023">developer conference on synthetic data</a> is happening this February. </li>


            <li>A comparison of <a href="https://arxiv.org/pdf/2201.01647.pdf">ML and several transformer methods</a> (DistilBERT, Pub- MedBERT) on the challenges of entity extraction and grammar patterns in biomedical literature. With some consideration towards the cost equation for annotation and cloud data processing.</li>


            <li>An <a href="https://futureoflife.org/podcast/roman-yampolskiy-on-the-uncontrollability-incomprehensibility-and-unexplainability-of-ai/">interview with Roman Yampolskiy</a>, Professor of Computer Science at the University of Louisville, discusses whether we can control, comprehend, and explain AI systems.</li>


            <li>A <a href="https://github.com/nlptechbook/BERTembeddings">toy example in Python</a> helps to decipher context and priority by extracting and evaluating pre-trained BERT embeddings.</li>
            </ul>
    </body>
</html>
